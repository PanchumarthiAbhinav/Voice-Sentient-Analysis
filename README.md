# Voice-Sentient-Analysis
## Identifying sentiment of the recorded voice

* The model is built using deep learning concepts
* Librosa library was used for extracting features from the input samples
* Later these features are used for classification of the voice into it's respective sentiments
*  The model was trained to identify only four major sentiments that are calm, happy, sad and fearful
*  The dataset used was [RAVDESS dataset](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0196391#:~:text=The%20RAVDESS%20is%20a%20validated,a%20neutral%20North%20American%20accent.) which consisted of voice recordings of 24 professional actors.
*  The model was able to produce and accuracy of 78% which is high compared to the ability of human to identify sentiment which is just slightly more than 60%.
* You can find the source code here [Model]()
